Virtual Mouse with Enhanced Gestures
Overview
This project introduces a gesture-based virtual mouse that enables users to control their cursor using hand gestures. The system leverages MediaPipe, OpenCV, and Python to track hand movements and translate them into mouse actions. Unlike traditional virtual mouse implementations, this project introduces new customizable gestures for improved accuracy, usability, and accessibility.

Features
âœ… Hand Gesture-Based Cursor Control
âœ… New Customizable Gestures (e.g., scroll, right-click, drag-and-drop)
âœ… Real-Time Hand Tracking using MediaPipe
âœ… AI-Powered Gesture Recognition
âœ… Works on Standard Webcam without Additional Hardware
âœ… Optimized for Low Latency and High Responsiveness

Installation
1. Clone the Repository
bash
Copy
Edit
git clone https://github.com/your-username/virtual-mouse-gestures.git
cd virtual-mouse-gestures
2. Install Dependencies
Ensure you have Python 3.x installed. Then, run:

bash
Copy
Edit
pip install opencv-python mediapipe pyautogui numpy
3. Run the Virtual Mouse
bash
Copy
Edit
python virtual_mouse.py
How It Works
The webcam captures the hand gestures.
MediaPipe detects the hand landmarks.
Predefined gestures are mapped to mouse actions like click, move, scroll, etc.
New gestures can be added and customized.
Newly Added Gestures
âœŒï¸ Two-Finger Scroll â†’ Scrolls up/down.
ğŸ¤š Palm Open â†’ Stops mouse movement.
ğŸ¤ Pinch & Drag â†’ Click and drag objects.
Future Enhancements
ğŸ”¹ Dynamic Gesture Learning using AI
ğŸ”¹ Multi-Hand Support
ğŸ”¹ Integration with Smart Home Devices
