import cv2
import mediapipe as mp
import pyautogui
import numpy as np
import time

mp_hands = mp.solutions.hands
mp_draw = mp.solutions.drawing_utils
hands = mp_hands.Hands(min_detection_confidence=0.7, min_tracking_confidence=0.7)

SCREEN_WIDTH, SCREEN_HEIGHT = pyautogui.size()

SMOOTHENING = 5
prev_x, prev_y = 0, 0

custom_gestures = {
    "fist": "right_click", 
    "three_fingers_up": "scroll_up",  
    "thumbs_up": "volume_up"  
}

def detect_custom_gesture(landmarks):
    """Detects custom gestures based on hand landmarks."""
    thumb_tip = landmarks[4]
    index_tip = landmarks[8]
    middle_tip = landmarks[12]
    ring_tip = landmarks[16]
    pinky_tip = landmarks[20]

    if all(landmarks[i].y > landmarks[i-2].y for i in [8, 12, 16, 20]):
        return "fist"

    if (index_tip.y < middle_tip.y < ring_tip.y) and (pinky_tip.y > ring_tip.y):
        return "three_fingers_up"

    if thumb_tip.y < index_tip.y and thumb_tip.y < middle_tip.y:
        return "thumbs_up"

    return None

cap = cv2.VideoCapture(0)

while cap.isOpened():
    ret, frame = cap.read()
    if not ret:
        break

    frame = cv2.flip(frame, 1)
    rgb_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)

    results = hands.process(rgb_frame)

    if results.multi_hand_landmarks:
        for hand_landmarks in results.multi_hand_landmarks:
            mp_draw.draw_landmarks(frame, hand_landmarks, mp_hands.HAND_CONNECTIONS)

            lm_list = hand_landmarks.landmark

            x, y = int(lm_list[8].x * SCREEN_WIDTH), int(lm_list[8].y * SCREEN_HEIGHT)

            cur_x = prev_x + (x - prev_x) // SMOOTHENING
            cur_y = prev_y + (y - prev_y) // SMOOTHENING

            pyautogui.moveTo(cur_x, cur_y)  

            prev_x, prev_y = cur_x, cur_y

            gesture = detect_custom_gesture(lm_list)
            if gesture in custom_gestures:
                action = custom_gestures[gesture]
                if action == "right_click":
                    pyautogui.rightClick()
                elif action == "scroll_up":
                    pyautogui.scroll(10)
                elif action == "volume_up":
                    pyautogui.press("volumeup")

    cv2.imshow("Virtual Mouse with Custom Gestures", frame)

    if cv2.waitKey(1) & 0xFF == ord('q'):
        break

cap.release()
cv2.destroyAllWindows()
